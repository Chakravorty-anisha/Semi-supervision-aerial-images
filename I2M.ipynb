{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e478e11b",
      "metadata": {
        "id": "e478e11b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36b81665",
      "metadata": {
        "id": "36b81665"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pickle\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import cv2\n",
        "import torch\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Input, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Add\n",
        "from keras.metrics import MeanIoU\n",
        "\n",
        "from os.path import join, isdir\n",
        "from os import listdir, rmdir\n",
        "from shutil import move, rmtree, make_archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c7b7b7",
      "metadata": {
        "id": "a3c7b7b7"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "use_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac55596d",
      "metadata": {
        "id": "ac55596d"
      },
      "outputs": [],
      "source": [
        "MAIN_DIR = \"path to labelled images\"\n",
        "GT_DIR = MAIN_DIR + \"masks/\"\n",
        "IMG_DIR =  MAIN_DIR + \"images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f7a9c30",
      "metadata": {
        "id": "5f7a9c30"
      },
      "outputs": [],
      "source": [
        "gt_train_paths = [GT_DIR+'training masks/' + path for path in listdir(GT_DIR+'training masks/')]\n",
        "gt_test_paths = [GT_DIR+'test masks/' + path for path in listdir(GT_DIR+'test masks/')]\n",
        "\n",
        "im_train_paths = [IMG_DIR+'training images/' + path for path in listdir(IMG_DIR+'training images/')]\n",
        "im_test_paths = [IMG_DIR+'test images/' + path for path in listdir(IMG_DIR+'test images')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab16ca7",
      "metadata": {
        "id": "9ab16ca7"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE1= 256\n",
        "IMG_SIZE2= 256\n",
        "def load_and_preprocess_image(path):\n",
        "    img = Image.open(path)\n",
        "    imarray = np.array(img, dtype = 'float')\n",
        "    if imarray.shape[0] != IMG_SIZE1 or imarray.shape[1] != IMG_SIZE2:\n",
        "        nimg = img.resize((IMG_SIZE1,IMG_SIZE2))\n",
        "        nimarray = np.array(nimg, dtype = 'float')\n",
        "        nimarray/=255.0\n",
        "        return tf.convert_to_tensor(nimarray)\n",
        "    imarray/=255.0\n",
        "    return tf.convert_to_tensor(imarray)\n",
        "\n",
        "def load_and_preprocess_mask(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "#     img = tf.image.resize(img, [IMG_SIZE1, IMG_SIZE2],method='nearest')\n",
        "    return img\n",
        "\n",
        "def load_and_preprocess_segment(path):\n",
        "    seg = np.array(load_and_preprocess_mask(path))\n",
        "    mask = np.zeros((IMG_SIZE1, IMG_SIZE2, len(colors)), dtype=np.uint8)\n",
        "    for i, color in enumerate(colors):\n",
        "        cmap = np.all(np.equal(seg, color), axis=-1)\n",
        "        mask[:, :, i] = cmap * 1\n",
        "    return tf.convert_to_tensor(mask)\n",
        "\n",
        "def get_image_paths(dir):\n",
        "    return sorted([dir + path for path in listdir(dir)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b4d766",
      "metadata": {
        "id": "14b4d766"
      },
      "outputs": [],
      "source": [
        "#if you want to define colours for the labels\n",
        "colors = [[0, 0, 128],\n",
        " [0, 0, 255],\n",
        " [0, 128, 0],\n",
        " [0, 128, 128],\n",
        " [0, 192, 255],\n",
        " [0, 255, 0],\n",
        " [0, 255, 255],\n",
        " [128, 0, 0],\n",
        " [128, 0, 128],\n",
        " [128, 128, 0],\n",
        " [164, 160, 160],\n",
        " [192, 0, 255],\n",
        " [233, 233, 255],\n",
        " [240, 202, 166],\n",
        " [255, 0, 0],\n",
        " [255, 87, 90],\n",
        " [255, 255, 0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fb083c",
      "metadata": {
        "id": "d1fb083c"
      },
      "outputs": [],
      "source": [
        "gt_train_paths = get_image_paths(GT_DIR+'training masks')\n",
        "gt_train_ds = list(map(load_and_preprocess_segment,gt_train_paths))\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices(gt_train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e580bca6",
      "metadata": {
        "id": "e580bca6"
      },
      "outputs": [],
      "source": [
        "gt_test_paths = get_image_paths(GT_DIR+'test masks')\n",
        "gt_test_ds = list(map(load_and_preprocess_segment,gt_test_paths))\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices(gt_test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f5cb84c",
      "metadata": {
        "id": "5f5cb84c"
      },
      "outputs": [],
      "source": [
        "im_train_ds = tf.data.Dataset.from_tensor_slices([load_and_preprocess_image(i) for i in get_image_paths(IMG_DIR+'training images')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade97e4d",
      "metadata": {
        "id": "ade97e4d"
      },
      "outputs": [],
      "source": [
        "im_test_ds = tf.data.Dataset.from_tensor_slices([load_and_preprocess_image(i) for i in get_image_paths(IMG_DIR+'test images')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "357e30c8",
      "metadata": {
        "id": "357e30c8"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97cfcfe",
      "metadata": {
        "id": "d97cfcfe"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "print('Training Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(train_ds), next(iter(train_ds))[0].shape, next(iter(train_ds))[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83640d1e",
      "metadata": {
        "id": "83640d1e"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Validation Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(test_ds), next(iter(test_ds))[0].shape, next(iter(test_ds))[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e8947a",
      "metadata": {
        "id": "16e8947a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)  # Convert y_true to float32\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n",
        "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n",
        "    return K.mean((2. * intersection + 1.) / (union + 1.))\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    # Categorical Crossentropy Loss\n",
        "    cat_cross_loss = categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # Dice Loss\n",
        "    dice_loss_value = dice_loss(y_true, y_pred)\n",
        "\n",
        "    # Combine the losses (you can adjust the weights as needed)\n",
        "    alpha = 0.5  # Weight for Categorical Crossentropy Loss\n",
        "    beta = 0.5   # Weight for Dice Loss\n",
        "    combined = alpha * cat_cross_loss + beta * dice_loss_value\n",
        "\n",
        "    return combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48f91eb",
      "metadata": {
        "id": "e48f91eb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def new_model_with_resnet50_encoder():\n",
        "    # Load pre-trained ResNet50 model (without top layers)\n",
        "    resnet50_encoder = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE1, IMG_SIZE2, 3))\n",
        "\n",
        "    # Freeze the layers in the ResNet50 encoder\n",
        "    for layer in resnet50_encoder.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Get the output from the ResNet50 encoder\n",
        "    resnet50_output = resnet50_encoder.output\n",
        "\n",
        "    x6 = UpSampling2D(size=(2, 2))(resnet50_output)\n",
        "    x6 = concatenate([resnet50_encoder.get_layer(\"conv4_block6_out\").output, x6])\n",
        "    x6 = Conv2D(1024, 3, activation=\"relu\", padding=\"same\")(x6)\n",
        "    x6 = Conv2D(512, 3, activation=\"relu\", padding=\"same\")(x6)\n",
        "\n",
        "    x7 = UpSampling2D(size=(2, 2))(x6)\n",
        "    x7 = concatenate([resnet50_encoder.get_layer(\"conv3_block4_out\").output, x7])\n",
        "    x7 = Conv2D(512, 3, activation=\"relu\", padding=\"same\")(x7)\n",
        "    x7 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x7)\n",
        "\n",
        "    x8 = UpSampling2D(size=(2, 2))(x7)\n",
        "    x8 = concatenate([resnet50_encoder.get_layer(\"conv2_block3_out\").output, x8])\n",
        "    x8 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x8)\n",
        "    x8 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x8)\n",
        "\n",
        "    x9 = UpSampling2D(size=(2, 2))(x8)\n",
        "    x9 = concatenate([resnet50_encoder.get_layer(\"conv1_relu\").output, x9])\n",
        "    x9 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x9)\n",
        "    x9 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x9)\n",
        "    x9 = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x9)\n",
        "\n",
        "    x9 = UpSampling2D(size=(2, 2))(x9)\n",
        "    x9 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x9)\n",
        "    x9 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x9)\n",
        "    x9 = Conv2D(17, 3, activation=\"softmax\", padding=\"same\")(x9)\n",
        "\n",
        "    # Create the new model\n",
        "    model = Model(inputs=resnet50_encoder.input, outputs=x9)\n",
        "\n",
        "    # Compile the model\n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=opt, loss=combined_loss, metrics=[MeanIoU(num_classes=17)])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Assuming IMG_SIZE1 and IMG_SIZE2 are defined\n",
        "IMG_SIZE1, IMG_SIZE2 = 256, 256\n",
        "\n",
        "my_new_model_with_resnet50 = new_model_with_resnet50_encoder()\n",
        "print(\"U-Net Model with ResNet50 Encoder Summary:\\n\")\n",
        "my_new_model_with_resnet50.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a5aebd",
      "metadata": {
        "id": "52a5aebd"
      },
      "outputs": [],
      "source": [
        "my_new_model_with_resnet50.fit(train_ds, epochs=100, validation_data=test_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb1d876",
      "metadata": {
        "id": "3fb1d876"
      },
      "outputs": [],
      "source": [
        "my_new_model.save(MAIN_DIR+'model_name')\n",
        "\n",
        "loss, acc = my_new_model.evaluate(test_ds, verbose=2)\n",
        "print(\"Retrained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c3377cf",
      "metadata": {
        "id": "8c3377cf"
      },
      "outputs": [],
      "source": [
        "gt_unl_paths = get_image_paths(GT_DIR+'predicted')\n",
        "gt_unl_ds = list(map(load_and_preprocess_segment,gt_unl_paths))\n",
        "gt_unl_ds = tf.data.Dataset.from_tensor_slices(gt_unl_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4028dbbc",
      "metadata": {
        "id": "4028dbbc"
      },
      "outputs": [],
      "source": [
        "im_unl_ds = tf.data.Dataset.from_tensor_slices([load_and_preprocess_image(i) for i in get_image_paths(IMG_DIR+'unlabelled images')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff97308",
      "metadata": {
        "id": "cff97308"
      },
      "outputs": [],
      "source": [
        "unl_ds = tf.data.Dataset.zip((im_unl_ds, gt_unl_ds))\n",
        "unl_ds = unl_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Training Data:\\n# of batches, Input batch shape, Output batch shape')\n",
        "print(len(unl_ds), next(iter(unl_ds))[0].shape, next(iter(unl_ds))[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b3426e",
      "metadata": {
        "id": "c5b3426e"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(MAIN_DIR+\"model_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0bedd4",
      "metadata": {
        "id": "7d0bedd4"
      },
      "outputs": [],
      "source": [
        "directory = \"path for predicted masks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e99a21",
      "metadata": {
        "id": "24e99a21"
      },
      "outputs": [],
      "source": [
        "os.chdir(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e28294",
      "metadata": {
        "id": "e7e28294"
      },
      "outputs": [],
      "source": [
        "a = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
        "def pre_process(index_img):\n",
        "    mask = np.zeros((IMG_SIZE1, IMG_SIZE2, len(colors)), dtype=np.uint8)\n",
        "    for i, color in enumerate(a):\n",
        "        cmap = index_img == color\n",
        "        mask[:, :, i] = cmap * 1\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3af5afa",
      "metadata": {
        "id": "a3af5afa"
      },
      "outputs": [],
      "source": [
        "def lrgb(img):\n",
        "    nimg = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "    for i in range(img.shape[2]):\n",
        "        c = img[:,:,i]\n",
        "        col = colors[i]\n",
        "        for j in range(3):\n",
        "            nimg[:,:,j]+=col[j]*c\n",
        "    nimg = nimg/255.0\n",
        "    return nimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b17eae6",
      "metadata": {
        "id": "7b17eae6"
      },
      "outputs": [],
      "source": [
        "def saveMasks(test_ds):\n",
        "    k = 0\n",
        "    paths = get_image_paths(GT_DIR+'sep/')\n",
        "    for imgs, segs in test_ds:\n",
        "        p = model.predict(imgs)\n",
        "        for i in range(p.shape[0]):\n",
        "            arg = np.argmax(p[i],axis = -1)\n",
        "            _s = pre_process(arg)\n",
        "            _p = lrgb(_s)\n",
        "#             _p = lrgb(p[i])\n",
        "            filename = paths[k].split(\"/\")[-1]\n",
        "            k+=1\n",
        "\n",
        "#             _p = cv2.convertScaleAbs(_p, alpha=(255.0))\n",
        "# #             cv.imwrite(path, img)\n",
        "#             cv2.imwrite(filename,_p)\n",
        "            plt.imsave(filename,_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "488573f0",
      "metadata": {
        "scrolled": false,
        "id": "488573f0"
      },
      "outputs": [],
      "source": [
        "p = model.predict(unl_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887bf89a",
      "metadata": {
        "id": "887bf89a"
      },
      "outputs": [],
      "source": [
        "arg = np.argmax(p[5],axis = -1)\n",
        "_s = pre_process(arg)\n",
        "_p = lrgb(_s)\n",
        "plt.imshow(_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b219aeb9",
      "metadata": {
        "id": "b219aeb9"
      },
      "outputs": [],
      "source": [
        "saveMasks(unl_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7eef3f8",
      "metadata": {
        "id": "e7eef3f8"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('model_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef9c514",
      "metadata": {
        "id": "5ef9c514"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(test_ds)\n",
        "pred = np.argmax(pred,axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "822edde5",
      "metadata": {
        "id": "822edde5"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoded_mask(path):\n",
        "    seg = np.array(load_and_preprocess_mask(path))\n",
        "    mask = np.zeros((IMG_SIZE1, IMG_SIZE2, 17), dtype=np.uint8)\n",
        "    for i, color in enumerate(colors):\n",
        "        cmap = np.all(np.equal(seg, color), axis=-1)\n",
        "        mask[:, :, i] = cmap * 1\n",
        "    return mask\n",
        "\n",
        "truth_val_masks = np.array([one_hot_encoded_mask(i) for i in gt_test_paths])\n",
        "truth_val_masks = np.argmax(truth_val_masks,axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0673da0",
      "metadata": {
        "id": "e0673da0"
      },
      "outputs": [],
      "source": [
        "def get_fn(target_img,pred_img,i):\n",
        "    tar = target_img == i\n",
        "    pre = pred_img==i\n",
        "    ans = (tar|pre) & ~pre\n",
        "    return sum(sum(ans))\n",
        "def get_fp(target_img,pred_img,i):\n",
        "    tar = target_img == i\n",
        "    pre = pred_img==i\n",
        "    ans = (tar|pre) & ~tar\n",
        "    return sum(sum(ans))\n",
        "def get_tp(target_img,pred_img,i):\n",
        "    tar = target_img == i\n",
        "    pre = pred_img==i\n",
        "    ans = tar&pre\n",
        "    return sum(sum(ans))\n",
        "\n",
        "def get_detailed_iou(target_img,pred_img,NUM_CLASS = 17):\n",
        "    iou_classes = np.zeros(17)\n",
        "    for i in range(17):\n",
        "        if(i in np.unique(target_img) and i in np.unique(pred_img)):\n",
        "            den = get_tp(target_img,pred_img,i)+get_fp(target_img,pred_img,i)+get_fn(target_img,pred_img,i)\n",
        "            if(den != 0):\n",
        "                iou_classes[i] = (get_tp(target_img,pred_img,i)/(get_tp(target_img,pred_img,i)+get_fp(target_img,pred_img,i)+get_fn(target_img,pred_img,i)))\n",
        "    return iou_classes\n",
        "\n",
        "def present_iou(iou_classes):\n",
        "    for i in range(len(iou_classes)):\n",
        "       print(colors[i], \" : \",iou_classes[i])\n",
        "\n",
        "\n",
        "def get_Mean_IOU_of_each_class():\n",
        "    classes_iou = np.zeros(17)\n",
        "    num_images_to_each_class = np.zeros(17)\n",
        "    for i in range(105):\n",
        "        ious = get_detailed_iou(truth_val_masks[i], pred[i])\n",
        "        for j in range(17):\n",
        "            classes_iou[j] += ious[j]\n",
        "        for j in np.unique(pred[i]):\n",
        "            num_images_to_each_class[j] += 1\n",
        "    for j in range(len(classes_iou)):\n",
        "        if(num_images_to_each_class[j] != 0):\n",
        "            classes_iou[j] /= num_images_to_each_class[j]\n",
        "\n",
        "    return classes_iou\n",
        "\n",
        "def show_top_IoUs(n:int):\n",
        "    classes_ious = get_Mean_IOU_of_each_class()\n",
        "    print(sorted(classes_ious))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82415ec",
      "metadata": {
        "scrolled": true,
        "id": "f82415ec"
      },
      "outputs": [],
      "source": [
        "present_iou(get_Mean_IOU_of_each_class())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bda42969",
      "metadata": {
        "id": "bda42969"
      },
      "outputs": [],
      "source": [
        "show_top_IoUs(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d0c8242",
      "metadata": {
        "id": "8d0c8242"
      },
      "source": [
        "#### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0ef535",
      "metadata": {
        "id": "8c0ef535"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(MAIN_DIR+\"model_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e7ffe2a",
      "metadata": {
        "id": "5e7ffe2a"
      },
      "outputs": [],
      "source": [
        "def LayersToRGBImage(img):\n",
        "    nimg = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "    for i in range(img.shape[2]):\n",
        "        c = img[:,:,i]\n",
        "        col = colors[i]\n",
        "\n",
        "        for j in range(3):\n",
        "            nimg[:,:,j]+=col[j]*c\n",
        "    nimg = nimg/255.0\n",
        "    return nimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4de7eb9",
      "metadata": {
        "id": "b4de7eb9"
      },
      "outputs": [],
      "source": [
        "max_show=6\n",
        "for imgs, segs in unl_ds:\n",
        "    p = model.predict(imgs)\n",
        "    for i in range(p.shape[0]):\n",
        "        if i > max_show:\n",
        "            break\n",
        "        _p = LayersToRGBImage(p[i])\n",
        "        _s = LayersToRGBImage(segs[i])\n",
        "        predimg = _p\n",
        "        trueimg = _s\n",
        "\n",
        "        plt.figure(figsize=(15,5))\n",
        "        plt.subplot(131)\n",
        "        plt.title(\"Actual Image\")\n",
        "        plt.imshow(imgs[i])\n",
        "\n",
        "        plt.subplot(132)\n",
        "        plt.title(\"Masked Image\")\n",
        "        plt.imshow(_s)\n",
        "        # plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(133)\n",
        "        plt.title(\"Predicted Image\")\n",
        "        plt.imshow(_p)\n",
        "        # plt.tight_layout()\n",
        "\n",
        "        plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2221a02a",
      "metadata": {
        "id": "2221a02a"
      },
      "source": [
        "Semi-supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabbc754",
      "metadata": {
        "id": "eabbc754"
      },
      "outputs": [],
      "source": [
        "gt_train_paths = get_image_paths(GT_DIR+'training original labelled +most confident masks/')\n",
        "gt_train_ds = list(map(load_and_preprocess_segment,gt_train_paths))\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices(gt_train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c4a027",
      "metadata": {
        "id": "86c4a027"
      },
      "outputs": [],
      "source": [
        "gt_test_paths = get_image_paths(GT_DIR+'testing original labelled +most confident masks/')\n",
        "gt_test_ds = list(map(load_and_preprocess_segment,gt_test_paths))\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices(gt_test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1f46fc",
      "metadata": {
        "id": "5a1f46fc"
      },
      "outputs": [],
      "source": [
        "im_train_ds = tf.data.Dataset.from_tensor_slices([load_and_preprocess_image(i) for i in get_image_paths(IMG_DIR+'training original labelled +most confident images/')])\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices([load_and_preprocess_image(i) for i in get_image_paths(IMG_DIR+'testing original labelled +most confident images/')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93bc948d",
      "metadata": {
        "id": "93bc948d"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "972889ad",
      "metadata": {
        "id": "972889ad"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Training Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(train_ds), next(iter(train_ds))[0].shape, next(iter(train_ds))[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "201882da",
      "metadata": {
        "id": "201882da"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.data.Dataset.zip((im_test_ds, gt_test_ds))\n",
        "test_ds = test_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print('Validation Data:\\n# of batches, Input batch shape, Ouput batch shape')\n",
        "print(len(test_ds), next(iter(test_ds))[0].shape, next(iter(test_ds))[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c29ed4",
      "metadata": {
        "id": "a1c29ed4"
      },
      "outputs": [],
      "source": [
        "my_new_model_with_resnet50.fit(train_ds, epochs=100, validation_data=test_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f016a12",
      "metadata": {
        "id": "2f016a12"
      },
      "outputs": [],
      "source": [
        "my_new_model.save(MAIN_DIR+'model_name')\n",
        "\n",
        "loss, acc = my_new_model.evaluate(test_ds, verbose=2)\n",
        "print(\"Retrained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4810a5c4",
      "metadata": {
        "id": "4810a5c4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}