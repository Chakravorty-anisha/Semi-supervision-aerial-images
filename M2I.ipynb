{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff8bc9af",
      "metadata": {
        "id": "ff8bc9af"
      },
      "outputs": [],
      "source": [
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from os import listdir\n",
        "from numpy import asarray, load\n",
        "from numpy import vstack\n",
        "from keras_preprocessing.image import img_to_array\n",
        "from keras_preprocessing.image import load_img\n",
        "from numpy import savez_compressed\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from keras import Input\n",
        "\n",
        "from keras.metrics import MeanIoU\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, Reshape, Lambda\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.layers import Cropping2D\n",
        "\n",
        "def define_encoder_block(layer_in, n_filters, resnet_model, prefix='encoder_'):\n",
        "    # Use the output of the last residual block as the output of the encoder block\n",
        "    resnet_output = resnet_model.get_layer('conv5_block3_out').output\n",
        "\n",
        "    # Additional convolutional layer for adapting the output channels to n_filters\n",
        "    conv = Conv2D(n_filters, (1, 1), strides=(1, 1), padding='same', name=prefix+'conv_adapt')(resnet_output)\n",
        "\n",
        "    # Batch normalization and LeakyReLU activation\n",
        "    conv = BatchNormalization(name=prefix+'batch_norm')(conv)\n",
        "    encoder_block_output = LeakyReLU(alpha=0.2, name=prefix+'leaky_relu')(conv)\n",
        "    return encoder_block_output\n",
        "\n",
        "from tensorflow.keras.layers import Cropping2D\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "\n",
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True, prefix='decoder_'):\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    print(\"enter decoder\")\n",
        "    print(layer_in)\n",
        "    # Upsample using UpSampling2D\n",
        "    #g = UpSampling2D(size=(2, 2), interpolation='nearest', name=prefix+'upsampling')(layer_in)\n",
        "    #print(g)\n",
        "    g = Conv2D(n_filters, (3, 3), strides=(1, 1), padding='same', kernel_initializer=init, name=prefix+'conv')(layer_in)\n",
        "    print(g)\n",
        "    g = BatchNormalization(name=prefix+'batch_norm')(g, training=True)\n",
        "    #print(g)\n",
        "    # Calculate cropping values\n",
        "    crop_size_y = max(0, (skip_in.shape[1] - g.shape[1]) // 2)\n",
        "    crop_size_x = max(0, (skip_in.shape[2] - g.shape[2]) // 2)\n",
        "\n",
        "    # Crop and concatenate with skip connection from the corresponding encoder block\n",
        "    skip_cropped = Cropping2D(cropping=((crop_size_y, crop_size_y), (crop_size_x, crop_size_x)))(skip_in)\n",
        "    g = Concatenate(name=prefix+'concatenate')([g, skip_cropped])\n",
        "\n",
        "    # Optional dropout layer\n",
        "    if dropout:\n",
        "        g = Dropout(0.5, name=prefix+'dropout')(g, training=True)\n",
        "\n",
        "    # Apply activation function (ReLU)\n",
        "    g = Activation('relu', name=prefix+'activation')(g)\n",
        "    print(g)\n",
        "    return g\n",
        "\n",
        "\n",
        "def define_unet_resnet50(resnet_model, image_shape=(256, 256, 3)):\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "\n",
        "    # Encoder\n",
        "    for layer in resnet_model.layers:\n",
        "        layer.trainable = False  # Freeze ResNet layers\n",
        "\n",
        "    e1 = resnet_model.get_layer('conv1_relu').output\n",
        "    e2 = resnet_model.get_layer('conv2_block3_out').output\n",
        "    e3 = resnet_model.get_layer('conv3_block4_out').output\n",
        "    e4 = resnet_model.get_layer('conv4_block6_out').output\n",
        "\n",
        "    # Decoder\n",
        "    d = Conv2DTranspose(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(e4)\n",
        "    d = Activation('relu')(d)\n",
        "    d = Concatenate()([d, e3])\n",
        "    d = Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
        "    d = Activation('relu')(d)\n",
        "    d = Concatenate()([d, e2])\n",
        "    d = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
        "    d = Activation('relu')(d)\n",
        "    d = Concatenate()([d, e1])\n",
        "\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    out_layer = Conv2DTranspose(image_shape[2], (4, 4), strides=(2, 2), padding='same', kernel_initializer=init, activation='tanh', name='output_image')(d)\n",
        "    out_image = Activation('tanh')( out_layer)\n",
        "    model = Model(resnet_model.input, out_image, name='generator')\n",
        "    #model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "image_shape = (256, 256, 3)\n",
        "# Create ResNet50 model without top layers\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
        "\n",
        "# Pass the ResNet50 model to the U-Net model\n",
        "unet_resnet50_model = define_unet_resnet50(resnet_model, image_shape)\n",
        "unet_resnet50_model.summary()\n",
        "opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "unet_resnet50_model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "953391d3",
      "metadata": {
        "id": "953391d3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n",
        "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n",
        "    return K.mean((2. * intersection + 1.) / (union + 1.))\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    # Categorical Crossentropy Loss\n",
        "    cat_cross_loss = categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # Dice Loss\n",
        "    dice_loss_value = dice_loss(y_true, y_pred)\n",
        "\n",
        "    # Combine the losses (you can adjust the weights as needed)\n",
        "    alpha = 0.5  # Weight for Categorical Crossentropy Loss\n",
        "    beta = 0.5   # Weight for Dice Loss\n",
        "    combined = alpha * cat_cross_loss + beta * dice_loss_value\n",
        "\n",
        "    return combined\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef12b70",
      "metadata": {
        "id": "8ef12b70"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Concatenate, Conv2D, LeakyReLU, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "\n",
        "def define_discriminator(image_shape):\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "\n",
        "    in_src_image = Input(shape=image_shape)\n",
        "    in_target_image = Input(shape=image_shape)\n",
        "\n",
        "    # Concatenate source and target images\n",
        "    merged = Concatenate()([in_src_image, in_target_image])\n",
        "\n",
        "    # Convolutional layers with LeakyReLU activation and batch normalization\n",
        "    d = Conv2D(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(merged)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "    d = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "    d = Conv2D(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "    d = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "    d = Conv2D(512, (4, 4), padding='same', kernel_initializer=init)(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "    d = Conv2D(1, (4, 4), padding='same', kernel_initializer=init)(d)\n",
        "    patch_out = Activation('sigmoid')(d)\n",
        "\n",
        "    # Define model\n",
        "    model = Model([in_src_image, in_target_image], patch_out)\n",
        "\n",
        "    # Compile the model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "discriminator_model = define_discriminator(image_shape)\n",
        "discriminator_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6191966",
      "metadata": {
        "id": "f6191966"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input\n",
        "\n",
        "# Combined generator and discriminator model for updating the generator\n",
        "def define_gan(generator_model, discriminator_model, image_shape):\n",
        "\n",
        "    input_image = Input(shape=image_shape)\n",
        "    generated_image = generator_model(input_image)\n",
        "    validity = discriminator_model([input_image, generated_image])\n",
        "\n",
        "    model = Model(inputs=input_image, outputs=[validity, generated_image])\n",
        "\n",
        "    model.compile(loss=['binary_crossentropy', 'mae'],\n",
        "               optimizer=opt, loss_weights=[1,100])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16be8c96",
      "metadata": {
        "id": "16be8c96"
      },
      "outputs": [],
      "source": [
        "# Create ResNet50 model without top layers for the generator\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
        "generator_model = define_unet_resnet50(resnet_model, image_shape)\n",
        "\n",
        "# Create discriminator model\n",
        "discriminator_model = define_discriminator(image_shape)\n",
        "\n",
        "\n",
        "# Define GAN model\n",
        "gan_model = define_gan(generator_model, discriminator_model, image_shape)\n",
        "\n",
        "# Print summary of the GAN model\n",
        "gan_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0e3222",
      "metadata": {
        "id": "8c0e3222"
      },
      "outputs": [],
      "source": [
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\ttrainA, trainB = dataset\n",
        "\tix = randint(0, trainA.shape[0], n_samples)\n",
        "\tX1, X2 = trainA[ix], trainB[ix]\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn [X1, X2], y\n",
        "\n",
        "def generate_fake_samples(g_model, samples, patch_shape):\n",
        "\tX = g_model.predict(samples)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51cf89a4",
      "metadata": {
        "id": "51cf89a4"
      },
      "outputs": [],
      "source": [
        "def summarize_performance(step, g_model, dataset, n_samples=3):\n",
        "\n",
        "\t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
        "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
        "\n",
        "\tX_realA = (X_realA + 1) / 2.0\n",
        "\tX_realB = (X_realB + 1) / 2.0\n",
        "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
        "\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_realA[i])\n",
        "\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + n_samples + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_fakeB[i])\n",
        "\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_realB[i])\n",
        "\n",
        "\tfilename1 = 'plot_%06d_691_Images.png' % (step+1)\n",
        "\tplt.savefig(filename1)\n",
        "\tplt.close()\n",
        "\n",
        "\tfilename2 = 'model_%06d_600_Images.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e190da13",
      "metadata": {
        "id": "e190da13"
      },
      "outputs": [],
      "source": [
        "def train(d_model, g_model, gan_model, dataset, n_epochs=10 , n_batch=1):\n",
        "\tn_patch = d_model.output_shape[1]\n",
        "\ttrainA, trainB = dataset\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
        "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
        "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
        "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
        "\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
        "\t\tif (i+1) % (bat_per_epo * 25) == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c294065",
      "metadata": {
        "id": "4c294065"
      },
      "outputs": [],
      "source": [
        "def load_mask_names(path):\n",
        "    src_list = list()\n",
        "    for filename in listdir(path):\n",
        "        src_list.append(filename)\n",
        "    src_list.sort()\n",
        "    return src_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c8b43dd",
      "metadata": {
        "id": "4c8b43dd"
      },
      "outputs": [],
      "source": [
        "def load_image_names(path):\n",
        "    tar_list = list()\n",
        "    for filename in listdir(path):\n",
        "        tar_list.append(filename)\n",
        "    tar_list.sort()\n",
        "    return tar_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6abbcc",
      "metadata": {
        "id": "1b6abbcc"
      },
      "outputs": [],
      "source": [
        "def load_masks(path, src_list_names , size=(256,256)):\n",
        "    src_list = list()\n",
        "    for fn in src_list_names:\n",
        "        for filename in listdir(path):\n",
        "            if fn == filename:\n",
        "                src_img = load_img(path + filename, target_size=size)\n",
        "                src_img = img_to_array(src_img)\n",
        "                src_list.append(src_img)\n",
        "                break\n",
        "\n",
        "    return asarray(src_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82686cb",
      "metadata": {
        "id": "a82686cb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e061a8",
      "metadata": {
        "id": "14e061a8"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE1 , IMG_SIZE2 = 256 , 256\n",
        "def load_images(path, tar_list_names , size=(256,256)):\n",
        "    tar_list = list()\n",
        "    for fn in tar_list_names:\n",
        "        for filename in listdir(path):\n",
        "            if fn == filename:\n",
        "                img = Image.open(path + filename)\n",
        "                imarray = np.array(img, dtype = 'float')\n",
        "                if imarray.shape[0] != IMG_SIZE1 or imarray.shape[1] != IMG_SIZE2:\n",
        "                    nimg = img.resize((IMG_SIZE1,IMG_SIZE2))\n",
        "                    imarray = np.array(nimg, dtype = 'float')\n",
        "                tar_list.append(imarray)\n",
        "                break\n",
        "    return asarray(tar_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c34dae9",
      "metadata": {
        "id": "1c34dae9"
      },
      "outputs": [],
      "source": [
        "path_train_images = 'path of labelled images'\n",
        "\n",
        "tar_images_names = load_image_names(path_train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd4ed11",
      "metadata": {
        "id": "4dd4ed11"
      },
      "outputs": [],
      "source": [
        "len(tar_images_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5027825",
      "metadata": {
        "id": "e5027825"
      },
      "outputs": [],
      "source": [
        "tar_images = load_images(path_train_images , tar_images_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2126fa12",
      "metadata": {
        "id": "2126fa12"
      },
      "outputs": [],
      "source": [
        "type(tar_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7260d19",
      "metadata": {
        "id": "a7260d19"
      },
      "outputs": [],
      "source": [
        "tar_images.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e3444f",
      "metadata": {
        "id": "a3e3444f"
      },
      "outputs": [],
      "source": [
        "path_train_masks = 'path of the masks of labelled set'\n",
        "\n",
        "src_images_names =  load_mask_names(path_train_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "842986af",
      "metadata": {
        "id": "842986af"
      },
      "outputs": [],
      "source": [
        "len(src_images_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ba07e1d",
      "metadata": {
        "id": "2ba07e1d"
      },
      "outputs": [],
      "source": [
        "src_images = load_masks(path_train_masks , src_images_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66168a04",
      "metadata": {
        "id": "66168a04"
      },
      "outputs": [],
      "source": [
        "type(src_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728f25c4",
      "metadata": {
        "id": "728f25c4"
      },
      "outputs": [],
      "source": [
        "src_images.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc14f2a",
      "metadata": {
        "id": "dcc14f2a"
      },
      "outputs": [],
      "source": [
        "print('Loaded: ', src_images.shape, tar_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4077a571",
      "metadata": {
        "id": "4077a571"
      },
      "outputs": [],
      "source": [
        "n_samples = 3\n",
        "for i in range(n_samples):\n",
        "\tplt.subplot(2, n_samples, 1 + i)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(src_images[i+201].astype('uint8'))\n",
        "\n",
        "for i in range(n_samples):\n",
        "\tplt.subplot(2, n_samples, 1 + n_samples + i)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(tar_images[i+201].astype('uint8'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e8d58d",
      "metadata": {
        "id": "18e8d58d"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data):\n",
        "\tX1, X2 = data[0], data[1]\n",
        "\n",
        "\tX1 = (X1 - 127.5) / 127.5\n",
        "\tX2 = (X2 - 127.5) / 127.5\n",
        "\treturn [X1, X2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99da44b",
      "metadata": {
        "id": "e99da44b"
      },
      "outputs": [],
      "source": [
        "data = [src_images , tar_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bb60279",
      "metadata": {
        "id": "2bb60279"
      },
      "outputs": [],
      "source": [
        "dataset = preprocess_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78c9068",
      "metadata": {
        "id": "e78c9068"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1f6149",
      "metadata": {
        "id": "ff1f6149"
      },
      "outputs": [],
      "source": [
        "train(discriminator_model, generator_model, gan_model, dataset, n_epochs=100, n_batch=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a313372",
      "metadata": {
        "id": "3a313372"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from numpy.random import randint\n",
        "\n",
        "model_path = 'model_path'\n",
        "\n",
        "model = load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd32da8",
      "metadata": {
        "id": "cfd32da8"
      },
      "outputs": [],
      "source": [
        "# plot source, generated and target images\n",
        "def plot_images(src_img, gen_img, tar_img):\n",
        "\timages = vstack((src_img, gen_img, tar_img))\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\timages = (images + 1) / 2.0\n",
        "\ttitles = ['Source', 'Generated', 'Expected']\n",
        "\t# plot images row by row\n",
        "\tplt.figure(figsize = (40,4))\n",
        "\tfor i in range(len(images)):\n",
        "\t\t# define subplot\n",
        "\n",
        "\t\tplt.subplot(1, 3 , 1 + i )\n",
        "\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(images[i])\n",
        "\t\tplt.title(titles[i])\n",
        "\tplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d1f649",
      "metadata": {
        "id": "f7d1f649",
        "outputId": "7d7a3111-419c-4cbe-f1f0-5726e26be349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "from numpy.random import randint\n",
        "\n",
        "model_path = '/home/semanticseg/Desktop/data_dlrsd/model_079100_600_Images.h5/'\n",
        "\n",
        "model = load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125ada9f",
      "metadata": {
        "id": "125ada9f"
      },
      "outputs": [],
      "source": [
        "path_train_images_test = 'path to unlabelled images'\n",
        "\n",
        "tar_images_names_test = load_image_names(path_train_images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b1e12b",
      "metadata": {
        "id": "a6b1e12b"
      },
      "outputs": [],
      "source": [
        "len(tar_images_names_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bddc6d1",
      "metadata": {
        "id": "4bddc6d1"
      },
      "outputs": [],
      "source": [
        "tar_images_test = load_images(path_train_images_test , tar_images_names_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5b8a41",
      "metadata": {
        "id": "1a5b8a41"
      },
      "outputs": [],
      "source": [
        "path_train_masks_test = 'path to predicted masks of unlabelled'\n",
        "\n",
        "src_images_names_test =  load_mask_names(path_train_masks_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7793d456",
      "metadata": {
        "id": "7793d456"
      },
      "outputs": [],
      "source": [
        "src_images_names_test = src_images_names_test[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d85b3f",
      "metadata": {
        "id": "34d85b3f"
      },
      "outputs": [],
      "source": [
        "len(src_images_names_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ab2ccd",
      "metadata": {
        "id": "c5ab2ccd"
      },
      "outputs": [],
      "source": [
        "src_images_test = load_masks(path_train_masks_test , src_images_names_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99edfcc7",
      "metadata": {
        "id": "99edfcc7"
      },
      "outputs": [],
      "source": [
        "print('Loaded: ', src_images_test.shape, tar_images_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c099b30d",
      "metadata": {
        "id": "c099b30d"
      },
      "outputs": [],
      "source": [
        "data_test = [src_images_test , tar_images_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d22326d1",
      "metadata": {
        "id": "d22326d1"
      },
      "outputs": [],
      "source": [
        "dataset_test = preprocess_data(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "189694ac",
      "metadata": {
        "id": "189694ac"
      },
      "outputs": [],
      "source": [
        "n_samples = 3\n",
        "for i in range(n_samples):\n",
        "\tplt.subplot(2, n_samples, 1 + i)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(src_images_test[13+i].astype('uint8'))\n",
        "\n",
        "for i in range(n_samples):\n",
        "\tplt.subplot(2, n_samples, 1 + n_samples + i)\n",
        "\tplt.axis('off')\n",
        "\tplt.imshow(tar_images_test[13+i].astype('uint8'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "389f9aa4",
      "metadata": {
        "id": "389f9aa4"
      },
      "outputs": [],
      "source": [
        "IOU_GeneratedMask = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94460a14",
      "metadata": {
        "id": "94460a14"
      },
      "outputs": [],
      "source": [
        "[X1 , X2] = dataset_test\n",
        "Iou_test = 0\n",
        "l = len(X1)\n",
        "for i in range(0 , l):\n",
        "    ix = np.array(i)\n",
        "    ix = ix.reshape((1,))\n",
        "\n",
        "    src_image, tar_image = X1[ix], X2[ix]\n",
        "    gen_image = model.predict(src_image)\n",
        "\n",
        "    gen_image = (gen_image + 1) / 2.0\n",
        "    tar_image = (tar_image + 1) / 2.0\n",
        "\n",
        "    plot_images(src_image, gen_image, tar_image)\n",
        "\n",
        "    file_name = tar_images_names_test[i];\n",
        "\n",
        "    num_classes = \"no.of classes\"\n",
        "    IOU_keras = MeanIoU(num_classes=num_classes)\n",
        "    temp = IOU_keras.update_state(tar_image, gen_image)\n",
        "    Iou_test = (IOU_keras.result().numpy())\n",
        "    IOU_GeneratedMask[file_name] = Iou_test\n",
        "    print(Iou_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3674d859",
      "metadata": {
        "id": "3674d859"
      },
      "outputs": [],
      "source": [
        "IOU_GeneratedMask_Dict = sorted(IOU_GeneratedMask.items(), key=lambda x: x[1], reverse=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IOU_GeneratedMask_Dict"
      ],
      "metadata": {
        "id": "6-jUW4khaEn-"
      },
      "id": "6-jUW4khaEn-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "uo_slJIsaQo5"
      },
      "id": "uo_slJIsaQo5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iou_list = list(IOU_GeneratedMask_Dict)\n",
        "\n",
        "iou_values = np.array([item[1] for item in iou_list])\n",
        "mean_iou = np.mean(iou_values)\n",
        "std_dev_iou = np.std(iou_values)\n",
        "for i, (name, iou) in enumerate(iou_list):\n",
        "    if iou >= mean_iou + std_dev_iou or iou <= mean_iou - std_dev_iou:\n",
        "        src_file = \"path of that image in unlabelled\" + name[0]\n",
        "        dst_file = \"path of most confident set of images\" +  name[0]\n",
        "        shutil.copy(src_file, dst_file)"
      ],
      "metadata": {
        "id": "-6ImaMHfbdbJ"
      },
      "id": "-6ImaMHfbdbJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in src_images_names:\n",
        "    src = 'path of predicted masks' + i\n",
        "    dst = 'path of most confident set of masks' + i\n",
        "\n",
        "    shutil.move(src, dst)"
      ],
      "metadata": {
        "id": "OOfZRmQublEa"
      },
      "id": "OOfZRmQublEa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}